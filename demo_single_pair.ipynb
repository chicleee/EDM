{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo EDM on a single pair of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import matplotlib.cm as cm\n",
    "from src.utils.plotting import make_matching_figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indoor Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.edm import EDM\n",
    "from src.config.default import get_cfg_defaults\n",
    "from src.utils.misc import lower_config\n",
    "\n",
    "config = get_cfg_defaults()\n",
    "data_cfg_path = \"configs/data/scannet_test_1500.py\"\n",
    "main_cfg_path = \"configs/edm/indoor/edm_base.py\"\n",
    "config.merge_from_file(main_cfg_path)\n",
    "config.merge_from_file(data_cfg_path)\n",
    "\n",
    "W, H = 640, 480\n",
    "config.EDM.COARSE.MCONF_THR = 0.2\n",
    "config.EDM.COARSE.BORDER_RM = 2\n",
    "\n",
    "_config = lower_config(config)\n",
    "matcher = EDM(config=_config[\"edm\"]).cuda()\n",
    "state_dict = torch.load(\"weights/edm_outdoor.ckpt\")[\"state_dict\"]\n",
    "matcher.load_state_dict(state_dict)\n",
    "matcher = matcher.eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load example images\n",
    "img0_pth = \"assets/scannet_sample_images/scene0707_00_15.jpg\"\n",
    "img1_pth = \"assets/scannet_sample_images/scene0707_00_45.jpg\"\n",
    "img0_bgr = cv2.imread(img0_pth)\n",
    "img1_bgr = cv2.imread(img1_pth)\n",
    "\n",
    "# For draw\n",
    "img0_rgb = img0_bgr[:, :, ::-1]\n",
    "img1_rgb = img1_bgr[:, :, ::-1]\n",
    "img0_rgb = cv2.resize(img0_rgb, (W, H))\n",
    "img1_rgb = cv2.resize(img1_rgb, (W, H))\n",
    "\n",
    "# For inference\n",
    "img0_raw = cv2.cvtColor(img0_bgr, cv2.COLOR_BGR2GRAY)\n",
    "img1_raw = cv2.cvtColor(img1_bgr, cv2.COLOR_BGR2GRAY)\n",
    "img0_raw = cv2.resize(img0_raw, (W, H))\n",
    "img1_raw = cv2.resize(img1_raw, (W, H))\n",
    "\n",
    "img0 = torch.from_numpy(img0_raw)[None][None].cuda() / 255.\n",
    "img1 = torch.from_numpy(img1_raw)[None][None].cuda() / 255.\n",
    "batch = {'image0': img0, 'image1': img1}\n",
    "\n",
    "# Inference with EDM and get prediction\n",
    "with torch.no_grad():\n",
    "    matcher(batch)\n",
    "\n",
    "mkpts0 = batch['mkpts0_f'].cpu().numpy()\n",
    "mkpts1 = batch['mkpts1_f'].cpu().numpy()\n",
    "mconf = batch['mconf'].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw\n",
    "color = cm.jet(mconf)\n",
    "text = [\n",
    "    'EDM',\n",
    "    'Matches: {}'.format(len(mkpts0)),\n",
    "]\n",
    "fig = make_matching_figure(img0_rgb, img1_rgb, mkpts0, mkpts1, color, text=text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outdoor Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.edm import EDM\n",
    "from src.config.default import get_cfg_defaults\n",
    "from src.utils.misc import lower_config\n",
    "\n",
    "config = get_cfg_defaults()\n",
    "data_cfg_path = \"configs/data/megadepth_test_1500.py\"\n",
    "main_cfg_path = \"configs/edm/outdoor/edm_base.py\"\n",
    "config.merge_from_file(main_cfg_path)\n",
    "config.merge_from_file(data_cfg_path)\n",
    "\n",
    "W, H = 832, 832\n",
    "config.EDM.COARSE.MCONF_THR = 0.2\n",
    "config.EDM.COARSE.BORDER_RM = 2\n",
    "config.EDM.TEST_RES_H = H\n",
    "config.EDM.TEST_RES_W = W\n",
    "\n",
    "_config = lower_config(config)\n",
    "matcher_out = EDM(config=_config['edm']).cuda()\n",
    "state_dict = torch.load(\"weights/edm_outdoor.ckpt\")[\"state_dict\"]\n",
    "matcher_out.load_state_dict(state_dict)\n",
    "matcher_out = matcher_out.eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load example images\n",
    "img0_pth = \"assets/phototourism_sample_images/united_states_capitol_26757027_6717084061.jpg\"\n",
    "img1_pth = \"assets/phototourism_sample_images/united_states_capitol_98169888_3347710852.jpg\"\n",
    "\n",
    "img0_bgr = cv2.imread(img0_pth)\n",
    "img1_bgr = cv2.imread(img1_pth)\n",
    "\n",
    "# For draw\n",
    "img0_rgb = img0_bgr[:, :, ::-1]\n",
    "img1_rgb = img1_bgr[:, :, ::-1]\n",
    "h0, w0 = img0_rgb.shape[:2]\n",
    "h1, w1 = img1_rgb.shape[:2]\n",
    "\n",
    "h0_scale = h0 / H\n",
    "w0_scale = w0 / W\n",
    "h1_scale = h1 / H\n",
    "w1_scale = w1 / W\n",
    "\n",
    "# For inference\n",
    "img0_raw = cv2.cvtColor(img0_bgr, cv2.COLOR_BGR2GRAY)\n",
    "img1_raw = cv2.cvtColor(img1_bgr, cv2.COLOR_BGR2GRAY)\n",
    "img0_raw = cv2.resize(img0_raw, (W, H))  # input size shuold be divisible by 32\n",
    "img1_raw = cv2.resize(img1_raw, (W, H))\n",
    "\n",
    "img0 = torch.from_numpy(img0_raw)[None][None].cuda() / 255.\n",
    "img1 = torch.from_numpy(img1_raw)[None][None].cuda() / 255.\n",
    "batch = {'image0': img0, 'image1': img1}\n",
    "\n",
    "# Inference with EDM and get prediction\n",
    "with torch.no_grad():\n",
    "    matcher_out(batch)\n",
    "\n",
    "mkpts0 = batch['mkpts0_f'].cpu().numpy()\n",
    "mkpts1 = batch['mkpts1_f'].cpu().numpy()\n",
    "mconf = batch['mconf'].cpu().numpy()\n",
    "mkpts0[:, 0] *= w0_scale\n",
    "mkpts0[:, 1] *= h0_scale\n",
    "mkpts1[:, 0] *= w1_scale\n",
    "mkpts1[:, 1] *= h1_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw\n",
    "color = cm.jet(mconf)\n",
    "text = [\n",
    "    'EDM',\n",
    "    'Matches: {}'.format(len(mkpts0)),\n",
    "]\n",
    "fig = make_matching_figure(img0_rgb, img1_rgb, mkpts0, mkpts1, color, text=text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
